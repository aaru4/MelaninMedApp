{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFFiIr9wDKiC"
      },
      "source": [
        "Download and Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "px9URA3e8OOM"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Subset\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision import transforms as T\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "means = [0.485, 0.456, 0.406]\n",
        "stds  = [0.229, 0.224, 0.225]\n",
        "test_transform = T.Compose([\n",
        "    lambda x: x.convert('RGB'),\n",
        "    T.Resize(299),\n",
        "    T.CenterCrop(299),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(mean=means, std=stds)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EjmloSjR9XIy"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "class DDI_Dataset(Dataset):\n",
        "    def __init__(self, root, csv_path=None, transform=None):\n",
        "        self.root = root\n",
        "        if csv_path is None:\n",
        "            csv_path = os.path.join(os.path.dirname(root), \"ddi_metadata.csv\")\n",
        "\n",
        "        # Load the annotations from the CSV file\n",
        "        self.annotations = pd.read_csv(csv_path)\n",
        "        self.image_files = self.annotations['DDI_file'].tolist()\n",
        "        self.transform = transform\n",
        "\n",
        "        # Add a 'malignant' column if it's not already present\n",
        "        m_key = 'malignant'\n",
        "        if m_key not in self.annotations:\n",
        "            self.annotations[m_key] = self.annotations['malignancy(malig=1)'].apply(lambda x: x == 1)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # Get the image file name and full path\n",
        "        file_name = self.image_files[index]\n",
        "        img_path = os.path.join(self.root, file_name)\n",
        "\n",
        "        # Load the image\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        # Get the annotation for this image\n",
        "        annotation = self.annotations.iloc[index]\n",
        "        target = int(annotation['malignant'])  # 1 if malignant, 0 if benign\n",
        "        skin_tone = annotation['skin_tone']    # Fitzpatrick- 12, 34, or 56\n",
        "\n",
        "        return img_path, img, target, skin_tone\n",
        "\n",
        "    def subset(self, skin_tone=None, diagnosis=None):\n",
        "        skin_tone = [12, 34, 56] if skin_tone is None else skin_tone\n",
        "        diagnosis = [\"benign\", \"malignant\"] if diagnosis is None else diagnosis\n",
        "\n",
        "        # Validate the provided skin tones and diagnoses\n",
        "        for si in skin_tone:\n",
        "            assert si in [12, 34, 56], f\"{si} is not a valid skin tone\"\n",
        "        for di in diagnosis:\n",
        "            assert di in [\"benign\", \"malignant\"], f\"{di} is not a valid diagnosis\"\n",
        "\n",
        "        # Filter the annotations based on skin tone and diagnosis\n",
        "        filtered_annotations = self.annotations[\n",
        "            (self.annotations['skin_tone'].isin(skin_tone)) &\n",
        "            (self.annotations['malignant'].isin([di == \"malignant\" for di in diagnosis]))\n",
        "        ]\n",
        "\n",
        "        # Get the indices of the filtered annotations\n",
        "        indices = filtered_annotations.index.tolist()\n",
        "\n",
        "        # Return a subset of the dataset based on the filtered indices\n",
        "        return Subset(self, indices)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "WiP71XMNArh9"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "root = '/content/DDI/images'\n",
        "dataset = DDI_Dataset(root=root, transform=test_transform)\n",
        "\n",
        "for i in range(5):\n",
        "    path, img, target, skin_tone = dataset[i]\n",
        "    print(f\"Image {i+1}:\")\n",
        "    print(f\"Path: {path}\")\n",
        "    print(f\"Target (Malignant: 1, Benign: 0): {target}\")\n",
        "    print(f\"Skin Tone: {skin_tone}\")\n",
        "\n",
        "    plt.imshow(img.permute(1, 2, 0))  # Permute the tensor dimensions to (H, W, C) for plotting\n",
        "    plt.title(f\"Target: {target}, Skin Tone: {skin_tone}\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "3iAS6W14O4Fg"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('/content/DDI/ddi_metadata.csv')\n",
        "\n",
        "df['disease_label'] = df['disease'].astype('category').cat.codes\n",
        "\n",
        "df.to_csv('/content/DDI/labeled_ddi_metadata.csv', index=False)\n",
        "\n",
        "print(df[['DDI_ID', 'disease', 'disease_label']].head())\n",
        "\n",
        "unique_labels = df[['disease', 'disease_label']].drop_duplicates().sort_values('disease_label')\n",
        "pd.set_option('display.max_rows', None)  # Show all rows\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "print(unique_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzVK7mcwDU0A"
      },
      "source": [
        "Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bOM_xc0Gkl_y"
      },
      "outputs": [],
      "source": [
        "pip install scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S6GsNcmEDy7K"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from torchvision import transforms as T\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision.models import vit_b_16, ViT_B_16_Weights\n",
        "\n",
        "# Define normalization parameters\n",
        "means = [0.485, 0.456, 0.406]\n",
        "stds = [0.229, 0.224, 0.225]\n",
        "test_transform = T.Compose([\n",
        "    T.Resize(224),\n",
        "    T.CenterCrop(224),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(mean=means, std=stds)\n",
        "])\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, root_dir, csv_file, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.data = pd.read_csv(csv_file)\n",
        "        self.transform = transform\n",
        "        self.image_paths = self.data['DDI_file'].values\n",
        "        self.labels = self.data['disease_label'].values\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.root_dir, str(self.image_paths[idx]))\n",
        "        img = Image.open(img_path).convert('RGB')\n",
        "        label = int(self.labels[idx])\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        return img, label\n",
        "\n",
        "\n",
        "# Load dataset and create dataloader\n",
        "root = '/content/DDI/images'\n",
        "csv_file = '/content/DDI/labeled_ddi_metadata.csv'\n",
        "dataset = CustomDataset(csv_file=csv_file, root_dir=root, transform=test_transform)\n",
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=4, pin_memory=True)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "\n",
        "class SqueezeExcitation(nn.Module):\n",
        "    def __init__(self, channels, reduction=16):\n",
        "        super(SqueezeExcitation, self).__init__()\n",
        "        self.fc1 = nn.Linear(channels, channels // reduction, bias=False)\n",
        "        self.fc2 = nn.Linear(channels // reduction, channels, bias=False)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Squeeze: Global Average Pooling\n",
        "        batch_size, num_channels, _, _ = x.size()\n",
        "        squeeze = nn.functional.adaptive_avg_pool2d(x, 1).view(batch_size, num_channels)\n",
        "\n",
        "        # Excitation\n",
        "        excitation = self.fc1(squeeze)\n",
        "        excitation = nn.functional.relu(excitation)\n",
        "        excitation = self.fc2(excitation)\n",
        "        excitation = self.sigmoid(excitation).view(batch_size, num_channels, 1, 1)\n",
        "\n",
        "        return x * excitation\n",
        "\n",
        "# ViT Adapter for 78-class classification\n",
        "class ViTAdapter(nn.Module):\n",
        "    def __init__(self, num_classes=78, reduction=16):\n",
        "        super(ViTAdapter, self).__init__()\n",
        "        self.vit = vit_b_16(weights=ViT_B_16_Weights.DEFAULT)\n",
        "        self.se = SqueezeExcitation(channels=self.vit.heads.head.in_features, reduction=reduction)\n",
        "        self.vit.heads = nn.Linear(self.vit.heads.head.in_features, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.vit(x)\n",
        "        return x\n",
        "\n",
        "# Initialize model\n",
        "model = ViTAdapter().to(device)\n",
        "model.train()\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()  # Multi-class classification loss\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "# Train the model\n",
        "def train_model(dataloader, model, criterion, optimizer, epochs=27):\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        for imgs, lbls in dataloader:\n",
        "            imgs, lbls = imgs.to(device), lbls.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(imgs)\n",
        "            loss = criterion(outputs, lbls)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item() * imgs.size(0)\n",
        "        epoch_loss = running_loss / len(dataloader.dataset)\n",
        "        print(f'Epoch {epoch+1}, Loss: {epoch_loss:.4f}')\n",
        "\n",
        "train_model(dataloader, model, criterion, optimizer)\n",
        "\n",
        "# Feature extraction function\n",
        "def extract_features(dataloader, model):\n",
        "    features = []\n",
        "    labels = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for imgs, lbls in dataloader:\n",
        "            imgs = imgs.to(device)\n",
        "            feature = model.vit(imgs)\n",
        "            features.append(feature.cpu().numpy())\n",
        "            labels.append(lbls.numpy())\n",
        "    return np.concatenate(features), np.concatenate(labels)\n",
        "\n",
        "# Extract features and split data\n",
        "features, labels = extract_features(dataloader, model)\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale features and train logistic regression\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "clf = LogisticRegression(max_iter=1000, solver='liblinear', C=1.0)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate accuracy\n",
        "y_pred = clf.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.5f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "# Generate confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred, labels=range(1, 79))\n",
        "\n",
        "# Initialize overall metrics\n",
        "total_tp = total_fn = total_fp = total_tn = 0\n",
        "\n",
        "# Calculate overall metrics\n",
        "for i in range(cm.shape[0]):\n",
        "    tp = cm[i, i]  # True positive\n",
        "    fn = cm[i, :].sum() - tp  # False negative\n",
        "    fp = cm[:, i].sum() - tp  # False positive\n",
        "    tn = cm.sum() - (fp + fn + tp)  # True negative\n",
        "\n",
        "    total_tp += tp\n",
        "    total_fn += fn\n",
        "    total_fp += fp\n",
        "    total_tn += tn\n",
        "\n",
        "# Calculate overall metrics\n",
        "overall_sensitivity = total_tp / (total_tp + total_fn) if (total_tp + total_fn) > 0 else 0\n",
        "overall_specificity = total_tn / (total_tn + total_fp) if (total_tn + total_fp) > 0 else 0\n",
        "overall_false_positive_rate = total_fp / (total_fp + total_tn) if (total_fp + total_tn) > 0 else 0\n",
        "overall_false_negative_rate = total_fn / (total_fn + total_tp) if (total_fn + total_tp) > 0 else 0\n",
        "\n",
        "# Print overall metrics\n",
        "print(f\"Overall Sensitivity: {overall_sensitivity:.4f}\")\n",
        "print(f\"Overall Specificity: {overall_specificity:.4f}\")\n",
        "print(f\"Overall False Positive Rate: {overall_false_positive_rate:.4f}\")\n",
        "print(f\"Overall False Negative Rate: {overall_false_negative_rate:.4f}\")\n"
      ],
      "metadata": {
        "id": "bhAy1y-eLNxZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np  # Ensure you import numpy for np.pad()\n",
        "\n",
        "# Define disease labels\n",
        "labels = [\n",
        "    'Abrasions Ulcerations and Physical Injuries', 'Abscess', 'Acne Cystic',\n",
        "    'Acquired Digital Fibrokeratoma', 'Acral Melanotic Macule', 'Acrochordon',\n",
        "    'Actinic Keratosis', 'Angioleiomyoma', 'Angioma', 'Arteriovenous Hemangioma',\n",
        "    'Atypical Spindle Cell Nevus of Reed', 'Basal Cell Carcinoma', 'Basal Cell Carcinoma Nodular',\n",
        "    'Basal Cell Carcinoma Superficial', 'Benign Keratosis', 'Blastic Plasmacytoid Dendritic Cell Neoplasm',\n",
        "    'Blue Nevus', 'Cellular Neurothekeoma', 'Chondroid Syringoma', 'Clear Cell Acanthoma',\n",
        "    'Coccidioidomycosis', 'Condyloma Accuminatum', 'Dermatofibroma', 'Dermatomyositis',\n",
        "    'Dysplastic Nevus', 'Eccrine Poroma', 'Eczema Spongiotic Dermatitis', 'Epidermal Cyst',\n",
        "    'Epidermal Nevus', 'Fibrous Papule', 'Focal Acral Hyperkeratosis', 'Folliculitis',\n",
        "    'Foreign Body Granuloma', 'Glomangioma', 'Graft Vs Host Disease', 'Hematoma',\n",
        "    'Hyperpigmentation', 'Inverted Follicular Keratosis', 'Kaposi Sarcoma', 'Keloid',\n",
        "    'Leukemia Cutis', 'Lichenoid Keratosis', 'Lipoma', 'Lymphocytic Infiltrations',\n",
        "    'Melanocytic Nevi', 'Melanoma', 'Melanoma Acral Lentiginous', 'Melanoma in Situ',\n",
        "    'Metastatic Carcinoma', 'Molluscum Contagiosum', 'Morphea', 'Mycosis Fungoides',\n",
        "    'Neurofibroma', 'Neuroma', 'Nevus Lipomatosus Superficialis', 'Nodular Melanoma (Nm)',\n",
        "    'Onychomycosis', 'Pigmented Spindle Cell Nevus of Reed', 'Prurigo Nodularis',\n",
        "    'Pyogenic Granuloma', 'Reactive Lymphoid Hyperplasia', 'Scar', 'Sebaceous Carcinoma',\n",
        "    'Seborrheic Keratosis', 'Seborrheic Keratosis Irritated', 'Solar Lentigo',\n",
        "    'Squamous Cell Carcinoma', 'Squamous Cell Carcinoma in Situ', 'Squamous Cell Carcinoma Keratoacanthoma',\n",
        "    'Subcutaneous T Cell Lymphoma', 'Syringocystadenoma Papilliferum', 'Tinea Pedis',\n",
        "    'Trichilemmoma', 'Trichofolliculoma', 'Verruca Vulgaris', 'Verruciform Xanthoma',\n",
        "    'Wart', 'Xanthogranuloma'\n",
        "]\n",
        "\n",
        "# Generate confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred, labels=range(1, 79))\n",
        "\n",
        "# Ensure cm has the correct shape (78, 78)\n",
        "if cm.shape != (78, 78):\n",
        "    cm = np.pad(cm, ((0, 78 - cm.shape[0]), (0, 78 - cm.shape[1])), mode='constant', constant_values=0)\n",
        "\n",
        "# Generate numeric labels\n",
        "numeric_labels = [str(i) for i in range(1, 79)]\n",
        "\n",
        "plt.figure(figsize=(20, 18))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=numeric_labels, yticklabels=numeric_labels)\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Lesion Diagnoser Confusion Matrix')\n",
        "plt.xticks(rotation=90)\n",
        "plt.yticks(rotation=0)\n",
        "\n",
        "# Adjust the legend to show disease names\n",
        "plt.subplots_adjust(right=0.85)\n",
        "plt.figtext(0.8, 0.03, \"\\n\".join(f\"{i+1}: {label}\" for i, label in enumerate(labels)), fontsize=12, ha='left')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Z3QBv-MNLRTC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fsQlMZXBLb7m"
      },
      "outputs": [],
      "source": [
        "!pip install coremltools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dmqn4SYZLfac"
      },
      "outputs": [],
      "source": [
        "import coremltools as ct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2pyzu9YuJt6q"
      },
      "outputs": [],
      "source": [
        "image_path = \"/content/DDI/images/000001.png\"\n",
        "def load_image(image_path, transform):\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    image = transform(image)\n",
        "    image = image.unsqueeze(0)\n",
        "    return image\n",
        "\n",
        "traceable_model = torch.jit.trace(model, load_image(image_path, test_transform).to(device))\n",
        "\n",
        "# Define the input type for Core ML conversion\n",
        "_input = ct.ImageType(\n",
        "    name=\"input_1\",\n",
        "    shape=(1, 3, 299, 299),\n",
        "    bias=[-m/s for m, s in zip(means, stds)],  # Bias correction (mean/std)\n",
        "    scale=1.0/(255.0 * stds[0])  # Scale correction (1/(255 * std))\n",
        ")\n",
        "\n",
        "# Convert to Core ML\n",
        "mlmodel = ct.convert(\n",
        "    traceable_model,\n",
        "    inputs=[_input]\n",
        ")\n",
        "\n",
        "mlmodel.user_defined_metadata['description'] = \"Skin lesion classification model (ResNet18)\"\n",
        "mlmodel.user_defined_metadata['version'] = \"1.0\"\n",
        "mlmodel.short_description = \"Classifies skin lesions as benign or malignant.\"\n",
        "\n",
        "# Save the model\n",
        "mlmodel.save(\"Diagnoser.mlpackage\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "geNDsrxsJu8R"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Move the model to Google Drive\n",
        "!mv Diagnoser.mlpackage/ /content/drive/My\\ Drive/"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyOO2uwdgO3TyJnufLNowvkK"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}